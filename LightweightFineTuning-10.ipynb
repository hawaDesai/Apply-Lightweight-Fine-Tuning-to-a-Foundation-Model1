{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: LORA\n",
    "* Model: GPT2\n",
    "* Evaluation approach: I decided to use something similar to the Bert sentient classifier we learned about in the course, but in relation to objectivity and fact. I found another model on huggingface that was trained for fact/objectivity or subjectivity/opinion, and I found it interesting to classify it as a sequence, referenced here: https://huggingface.co/lighteternal/fact-or-opinion-xlmr-el\n",
    "* Fine-tuning dataset: I used the \"nyu-mll/glue\" dataset that met CoLA GLUE benchmark: https://huggingface.co/datasets/nyu-mll/glue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0160266a847149dab367a030de8b632d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc6bc290d474b83a2aef45329f1affe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f09b6e9421406cad4de5cbc0b88356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92925389d8294ffc9dcaa5522a5dc11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b8ac7b101c4ed4a771e7c64064fabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c57e5d294924dcbb94b24d08feb0d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc1864c49a24bb598a0cd313ac4b6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 251k/251k [00:00<00:00, 2.52MB/s]\n",
      "Downloading data: 100%|██████████| 37.6k/37.6k [00:00<00:00, 407kB/s]\n",
      "Downloading data: 100%|██████████| 37.7k/37.7k [00:00<00:00, 391kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea83b3df38c4ee6b5833f147de1bb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de89acc15ca48c7b7c9c45cbfc87bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d3854b1b964b6d9023a47bfb6203c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForSequenceClassification.from_pretrained('gpt2',\n",
    "                                                      #num_labels = 2,\n",
    "                                                      #id2label = {0: \"Opinion/Subjective sentence\", 1:\"Fact/Objective sentence\"},\n",
    "                                                      #label2id = {\"Opinion/Subjective sentence\":0, \"Fact/Objective sentence\":1}\n",
    "                                                      )\n",
    "\n",
    "dataset =  load_dataset(\"nyu-mll/glue\", 'cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentence: food is scrappy\n",
      "\n",
      "There is a 100.00% chance that it is an Opinion/Subjective sentence\n",
      "Test Sentence:  One more pseudo generalization and I'm giving up.\n",
      "\n",
      "There is a 100.00% chance that it is an Opinion/Subjective sentence\n"
     ]
    }
   ],
   "source": [
    "input = tokenizer(\"Food is scrappy\", return_tensors = 'pt')\n",
    "\n",
    "print(\"Test Sentence: food is scrappy\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input).logits\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities)\n",
    "\n",
    "if predicted_class == 1:\n",
    "    print(f\"\\nThere is a {probabilities[0][0] * 100:.2f}% chance that it is a Fact/Objective sentence\")\n",
    "else:\n",
    "    print(f\"\\nThere is a {probabilities[0][0] * 100:.2f}% chance that it is an Opinion/Subjective sentence\")\n",
    "    \n",
    "input = tokenizer(dataset['train'][1]['sentence'], return_tensors = 'pt')\n",
    "\n",
    "print(\"Test Sentence: \",dataset['train'][1]['sentence'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input).logits\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities)\n",
    "\n",
    "if predicted_class == 1:\n",
    "    print(f\"\\nThere is a {probabilities[0][0] * 100:.2f}% chance that it is a Fact/Objective sentence\")\n",
    "else:\n",
    "    print(f\"\\nThere is a {probabilities[0][0] * 100:.2f}% chance that it is an Opinion/Subjective sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf839386e19c4e5395645842b966648a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5d10be8e3a493ab8d6cd0d246857d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['train'] = dataset['train'].select(range(500))\n",
    "dataset['test'] = dataset['test'].select(range(500))\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sentence'], padding = True, truncation=True, return_tensors = \"pt\")\n",
    "tokenized_ds = {}\n",
    "\n",
    "\n",
    "tokenized_ds['train'] = dataset['train'].map(tokenize_function, batched=True)\n",
    "tokenized_ds['test'] = dataset['test'].map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig\n",
    "from peft import get_peft_model\n",
    "\n",
    "\n",
    "config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                   r = 8,\n",
    "                   lora_dropout=0.01,\n",
    "                   )\n",
    "\n",
    "lora_model = get_peft_model(model, config)\n",
    "# used link below to fix issue with batch > -1 =, used eos_toke_id\n",
    "# https://stackoverflow.com/questions/68084302/assertionerror-cannot-handle-batch-sizes-1-if-no-padding-token-is-defined\n",
    "lora_model.config.pad_token_id = lora_model.config.eos_token_id \n",
    "\n",
    "for param in lora_model.parameters():\n",
    "    param.requires_grade = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d955e0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>0.658000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./data_save/checkpoint-250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = {\"accuracy\": (predictions == labels).mean()}\n",
    "    return accuracy\n",
    "\n",
    "trainer_model = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data_save\",\n",
    "        learning_rate=2e-3,\n",
    "        # Reduce the batch size if you don't have enough memory\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        #changed save and evaluation strategy by referencing this article \n",
    "        #recommended by the tech help section in our circle community:\n",
    "        # https://community.udacity.com/c/externship-tech-help/train-peft-model-bug-i-can-train-my-model-and\n",
    "        save_strategy=\"epoch\", \n",
    "        evaluation_strategy=\"epoch\", \n",
    "        load_best_model_at_end = True,\n",
    "        remove_unused_columns = True\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, return_tensors = \"pt\"),\n",
    "    compute_metrics=compute_metrics,\n",
    "   \n",
    ")\n",
    "\n",
    "trainer_model.train()\n",
    "model.save_pretrained(\"pre_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31a43c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.797381</td>\n",
       "      <td>0.658000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./data_save/checkpoint-250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "trainer_lora = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data_save\",\n",
    "        learning_rate=2e-3,\n",
    "        # Reduce the batch size if you don't have enough memory\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        #changed save and evaluation strategy by referencing this article \n",
    "        #recommended by the tech help section in our circle community:\n",
    "        # https://community.udacity.com/c/externship-tech-help/train-peft-model-bug-i-can-train-my-model-and\n",
    "        save_strategy=\"epoch\", \n",
    "        evaluation_strategy=\"epoch\", \n",
    "        load_best_model_at_end = True,\n",
    "        remove_unused_columns = True\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, return_tensors = \"pt\"),\n",
    "    compute_metrics=compute_metrics,\n",
    "   \n",
    ")\n",
    "\n",
    "trainer_lora.train()\n",
    "\n",
    "lora_model.save_pretrained(\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at pre_trained were not used when initializing GPT2ForSequenceClassification: ['transformer.h.6.attn.c_attn.lora_A.default.weight', 'transformer.h.9.attn.c_attn.lora_A.default.weight', 'transformer.h.5.attn.c_attn.lora_A.default.weight', 'transformer.h.7.attn.c_attn.lora_A.default.weight', 'transformer.h.5.attn.c_attn.lora_B.default.weight', 'score.original_module.weight', 'transformer.h.7.attn.c_attn.lora_B.default.weight', 'transformer.h.11.attn.c_attn.lora_B.default.weight', 'transformer.h.2.attn.c_attn.lora_B.default.weight', 'transformer.h.3.attn.c_attn.lora_A.default.weight', 'transformer.h.10.attn.c_attn.lora_A.default.weight', 'transformer.h.1.attn.c_attn.lora_B.default.weight', 'transformer.h.6.attn.c_attn.lora_B.default.weight', 'transformer.h.11.attn.c_attn.lora_A.default.weight', 'transformer.h.4.attn.c_attn.lora_B.default.weight', 'transformer.h.8.attn.c_attn.lora_B.default.weight', 'transformer.h.9.attn.c_attn.lora_B.default.weight', 'transformer.h.10.attn.c_attn.lora_B.default.weight', 'transformer.h.4.attn.c_attn.lora_A.default.weight', 'transformer.h.3.attn.c_attn.lora_B.default.weight', 'score.modules_to_save.default.weight', 'transformer.h.2.attn.c_attn.lora_A.default.weight', 'transformer.h.0.attn.c_attn.lora_A.default.weight', 'transformer.h.1.attn.c_attn.lora_A.default.weight', 'transformer.h.0.attn.c_attn.lora_B.default.weight', 'transformer.h.8.attn.c_attn.lora_A.default.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at pre_trained and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt-lora\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"pre_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df6f3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the pretrained model is: 0.658\n",
      "The accuracy of the lora model is: 0.658\n"
     ]
    }
   ],
   "source": [
    "eval_lora = trainer_lora.evaluate()\n",
    "eval_trainer = trainer_model.evaluate()\n",
    "print(\"The accuracy of the pretrained model is:\", eval_trainer['eval_accuracy'])\n",
    "print(\"The accuracy of the lora model is:\" ,eval_lora['eval_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
